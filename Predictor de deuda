import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Definición manual de los datos
data_manual = {
    'credit.policy': [
        1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
        11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
        21, 22, 23, 24, 25, 26, 27, 28, 29, 30,
        31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
        41, 42, 43, 44, 45, 46, 47, 48, 49, 50,
        51, 52, 53, 54, 55, 56, 57, 58, 59, 60,
        61, 62, 63, 64, 65, 66, 67, 68, 69, 70,
        71, 72, 73, 74, 75, 76, 77, 78, 79, 80,
        81, 82, 83, 84, 85, 86, 87, 88, 89, 90,
        91, 92, 93, 94, 95, 96, 97, 98, 99, 100,
        101, 102, 103, 104, 105, 106, 107, 108, 109, 110,
        111, 112, 113, 114, 115, 116, 117, 118, 119, 120,
        121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
        131, 132, 133, 134, 135, 136, 137, 138, 139, 140,
        141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
        151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
        161, 162, 163, 164, 165, 166, 167, 168, 169, 170,
        171, 172, 173, 174, 175, 176, 177, 178, 179, 180,
        181, 182, 183, 184, 185, 186, 187, 188, 189, 190,
        191, 192, 193, 194, 195, 196, 197, 198, 199, 200,
        201, 202, 203, 204, 205, 206, 207, 208, 209, 210,
        211, 212, 213, 214, 215, 216, 217, 218, 219, 220,
        221, 222, 223, 224, 225, 226, 227, 228, 229, 230,
        231, 232, 233, 234, 235, 236, 237, 238, 239, 240,
        241, 242, 243, 244, 245, 246, 247, 248, 249, 250,
        251, 252, 253, 254, 255, 256, 257, 258, 259, 260,
        261, 262, 263, 264, 265, 266, 267, 268, 269, 270,
        271, 272, 273, 274, 275, 276, 277, 278, 279, 280,
        281, 282, 283, 284, 285, 286, 287, 288, 289, 290,
        291, 292, 293, 294, 295, 296, 297, 298, 299, 300,
        301, 302, 303, 304, 305, 306, 307, 308, 309, 310,
        311, 312, 313, 314, 315, 316, 317, 318, 319, 320,
        321, 322, 323, 324, 325, 326, 327, 328, 329, 330,
        331, 332, 333, 334, 335, 336, 337, 338, 339, 340,
        341, 342, 343, 344, 345, 346, 347, 348, 349, 350,
        351, 352, 353, 354, 355, 356, 357, 358, 359, 360
    ],
    'installment': [
        829.1, 228.22, 366.86, 162.34, 102.92, 125.13, 194.02, 131.22, 87.19, 84.12,
        360.43, 253.58, 316.11, 92.82, 209.54, 327.53, 77.69, 476.58, 584.12, 173.65,
        188.02, 474.42, 339.6, 484.85, 320.19, 159.03, 155.38, 255.43, 155.38, 155.38,
        156.84, 275.38, 155.38, 78.42, 158.3, 155.38, 155.38, 164.23, 161.25, 159.77,
        156.84, 155.38, 94.98, 97.2, 164.23, 167.02, 168.6, 160.72, 159.03, 178.69,
        155.38, 323.98, 813.65, 112.87, 94.88, 398.69, 39.6, 678.08, 401.37, 205.45,
        397.75, 155.38, 113.39, 99.44, 109.79, 32.55, 112.87, 160.51, 340.57, 156.11,
        155.38, 235.25, 257.99, 225.37, 80.26, 84.0, 507.46, 124.31, 63.32, 130.79,
        93.67, 93.67, 88.65, 128.41, 94.98, 179.8, 444.05, 124.89, 644.3, 642.02, 104.76,
        157.66, 383.87, 217.6, 297.99, 156.11, 329.95, 313.67, 297.99, 239.65, 61.87,
        94.47, 73.68, 313.67, 543.2, 313.67, 266.37, 210.6, 234.15, 323.99, 235.96, 352.22,
        117.31, 64.96, 699.69, 195.27, 295.59, 217.59, 263.09, 248.43, 194.4, 301.04, 163.92, 150.66, 217.59, 85.23, 328.43, 165.47, 140.6, 98.01, 166.48, 284.32, 194.15, 138.51,
        70.25, 252.1, 263.19, 104.65, 172.53, 38.7, 100.35, 335.98, 163.49, 32.25, 96.75, 72.42, 90.68, 259.58, 169.32, 205.4,
        162.01, 226.8, 162.73, 158.38, 795.11, 158.83, 97.2, 263.97, 404.62, 307.53, 839.95, 269.31, 265.18, 802.47, 505.16, 318.05,
        315.12, 130.79, 227.82, 643.36, 51.78, 572.48, 149.87, 96.75, 92.8, 192.09, 593.92, 392.36, 156.11, 155.52, 485.99, 116.64,
        223.34, 149.87, 211.17, 186.45, 790.86, 795.11, 126.65, 294.27, 404.62, 397.77, 178.68, 29.16, 417.62, 130.18, 98.53,
        15.69, 523.14, 557.23, 315.3, 527.93, 93.23, 202.94, 165.74, 158.76, 485.99, 322.49, 189.97, 376.24, 599.33, 132.35, 828.69, 604.88, 538.23, 172.55, 604.88, 290.24, 530.36, 158.31, 390.54, 301.04, 659.91, 217.52, 388.79, 158.31, 319.64, 103.68, 154.08, 650.9, 81.74, 238.54, 335.98, 93.23, 95.87, 95.94, 554.37, 859.07, 472.68, 586.9, 224.69, 483.81, 399.55, 232.04,
        802.47, 304.9, 836.23, 124.89, 113.4, 842.47, 817.41, 421.65, 575.17, 405.03, 167.99, 677.22, 131.99, 281.2, 802.47, 505.16,
        180.23, 798.84, 319.54, 32.1, 192.6, 764.64, 30.94, 381.66, 301.04, 687.25, 320.99, 862.97, 250.95, 87.01, 62.45, 851.41,
        244.09, 687.25, 656.86, 537.57, 320.99, 386.99, 315.12, 292.91, 125.48, 383.45, 523.78, 199.78, 575.17, 95.42, 477.07,
        345.06, 155.19, 644.97, 92.8, 306.36, 143.53, 288.89, 87.88, 381.66, 197.06, 83.92, 481.48, 253.16, 77.69, 97, 259.87,
        124.3, 67.68, 406.07, 241.41, 170.72, 293.85, 318.09, 63.79, 217.52, 667.74, 133.55, 421.14, 339.94, 365.51, 313.69, 876.83,
        316.99, 701.12, 485, 133.55, 362.39, 108.27, 240.39, 62.15, 66.18, 327.82, 69.14, 313.3, 329.34, 292.97, 315.12, 225.86,
        63.03, 536.57, 126.29, 192.23, 97, 318.93, 228.45, 72.78, 16.47, 124.89, 262.26, 236.34, 265.87, 101.47, 218.55, 38.8, 247,
        673.79, 79.96, 498.51, 692.14
    ]
}

# Verificar la longitud de las listas en el diccionario
len_credit_policy = len(data_manual['credit.policy'])
len_installment = len(data_manual['installment'])


# Ajustar la longitud de la lista más corta (aquí se recortan los elementos sobrantes)
min_length = min(len_credit_policy, len_installment)
data_manual['credit.policy'] = data_manual['credit.policy'][:min_length]
data_manual['installment'] = data_manual['installment'][:min_length]

# Convertir a dataframe de Pandas
df = pd.DataFrame(data_manual)
# Eliminar filas con datos nulos
df.dropna(inplace=True)

# Detectar y eliminar outliers
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

df = remove_outliers(df, 'credit.policy')
df = remove_outliers(df, 'installment')

# Normalización de los datos
scaler = MinMaxScaler()
df_scaled = scaler.fit_transform(df[['credit.policy', 'installment']])
df['credit.policy'] = df_scaled[:, 0]
df['installment'] = df_scaled[:, 1]

# Definición de los datos de entrada y salida normalizados
X = np.array(df['credit.policy'])
y = np.array(df['installment'])

# Creación del modelo perceptrón
model = keras.Sequential([
    keras.layers.Dense(units=1, input_shape=[1])
])

# Compilación del modelo
model.compile(optimizer='sgd', loss='mean_squared_error')

# Entrenamiento del modelo
epochs = 3000
history = model.fit(X, y, epochs=epochs, verbose=0)

# Predicción para credit.policy de 370 (debe ser normalizado)
credit_policy_norm = scaler.transform([[370, 0]])[0][0]
prediction = model.predict([credit_policy_norm])
# Invertimos la normalización para obtener la predicción real
prediction_real = scaler.inverse_transform([[0, prediction[0][0]]])[0][1]
print(f"El installment predicho para credit.policy de 370 es: {prediction_real}")

# Graficar el historial de pérdida
plt.plot(history.history['loss'])
plt.xlabel('Epochs')
plt.ylabel('Loss Magnitude')
plt.title('Historial de Pérdida durante el Entrenamiento')
plt.show()
